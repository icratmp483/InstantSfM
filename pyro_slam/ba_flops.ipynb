{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming data for ladybug...\n",
      "Fetched problem-1723-156502-pre from ladybug\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import warnings\n",
    "from typing import Callable, List, Optional\n",
    "from torch.library import Library\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import Compose\n",
    "from datapipes.bal_loader import get_problem, read_bal_data\n",
    "\n",
    "TARGET_DATASET = \"ladybug\"\n",
    "TARGET_PROBLEM = \"problem-1723-156502-pre\"\n",
    "\n",
    "DEVICE = 'cuda' # change device to CPU if needed\n",
    "DTYPE = torch.float64\n",
    "USE_QUATERNIONS = True\n",
    "OPTIMIZE_INTRINSICS = False\n",
    "#dataset = read_bal_data(file_name='Data/dubrovnik-3-7-pre.txt', use_quat=USE_QUATERNIONS)\n",
    "dataset = get_problem(TARGET_PROBLEM, TARGET_DATASET, use_quat=USE_QUATERNIONS)\n",
    "\n",
    "if OPTIMIZE_INTRINSICS:\n",
    "    NUM_CAMERA_PARAMS = 10 if USE_QUATERNIONS else 9\n",
    "else:\n",
    "    NUM_CAMERA_PARAMS = 7 if USE_QUATERNIONS else 6\n",
    "\n",
    "print(f'Fetched {TARGET_PROBLEM} from {TARGET_DATASET}')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pypose as pp\n",
    "\n",
    "trimmed_dataset = dataset\n",
    "trimmed_dataset = {k: v.to(DEVICE) for k, v in trimmed_dataset.items() if type(v) == torch.Tensor}\n",
    "\n",
    "def convert_to(type):\n",
    "    for k, v in trimmed_dataset.items():\n",
    "        if 'index' not in k:\n",
    "            trimmed_dataset[k] = v.to(type)\n",
    "\n",
    "\n",
    "convert_to(DTYPE)\n",
    "torch.set_default_dtype(DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LD_LIBRARY_PATH'] = '/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/torch/lib:' + os.environ.get('LD_LIBRARY_PATH', '')\n",
    "os.environ['LD_LIBRARY_PATH'] = '/global/homes/h/hxu398/bal_exp/pyro_slam/cudss:' + os.environ.get('LD_LIBRARY_PATH', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W OperatorEntry.cpp:153] Warning: Warning only once for all operators,  other operators may also be overrided.\n",
      "  Overriding a previously registered kernel for the same operator and the same dispatch key\n",
      "  operator: aten::mm(Tensor self, Tensor mat2) -> Tensor\n",
      "    registered at /pscratch/sd/s/swowner/pytorch-build/pytorch/2.3.1/pytorch/build/aten/src/ATen/RegisterSchema.cpp:6\n",
      "  dispatch key: SparseCsrCPU\n",
      "  previous kernel: registered at /pscratch/sd/s/swowner/pytorch-build/pytorch/2.3.1/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1079\n",
      "       new kernel: registered at /global/u1/h/hxu398/bal_exp/pyro_slam/pyro_slam/sparse/sparse_op_cpp.cpp:206 (function operator())\n"
     ]
    }
   ],
   "source": [
    "from pyro_slam.sparse.py_ops import *\n",
    "from pyro_slam.sparse.bsr_cuda import *\n",
    "from pyro_slam.sparse.solve import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def rotate_euler(points, rot_vecs):\n",
    "    \"\"\"Rotate points by given rotation vectors.\n",
    "\n",
    "    Rodrigues' rotation formula is used.\n",
    "    \"\"\"\n",
    "    theta = torch.norm(rot_vecs, dim=1, keepdim=True) # 3 element-wise ops, square, sum, divide by norm\n",
    "    v = torch.nan_to_num(rot_vecs / theta) # 1 element-wise op, division\n",
    "    dot = torch.sum(points * v, dim=1, keepdim=True) # 2 element-wise ops\n",
    "    cos_theta = torch.cos(theta) # 1 element-wise op\n",
    "    sin_theta = torch.sin(theta) # 1 element-wise op\n",
    "    return cos_theta * points + sin_theta * torch.cross(v, points, dim=1) + dot * (1 - cos_theta) * v # 6 element-wise ops\n",
    "\n",
    "def rotate_quat(points, rot_vecs):\n",
    "    rot_vecs = pp.SE3(rot_vecs)\n",
    "    return rot_vecs.Act(points)\n",
    "\n",
    "def project(points, camera_params):\n",
    "    \"\"\"Convert 3-D points to 2-D by projecting onto images.\"\"\"\n",
    "    if USE_QUATERNIONS:\n",
    "        points_proj = rotate_quat(points, camera_params[..., :7])\n",
    "    else:\n",
    "        points_proj = rotate_euler(points, camera_params[..., 3:6])\n",
    "        points_proj = points_proj + camera_params[..., 3:6]\n",
    "    points_proj = -points_proj[..., :2] / points_proj[..., 2].unsqueeze(-1)  # add dimension for broadcasting\n",
    "    f = camera_params[..., -3].unsqueeze(-1)\n",
    "    k1 = camera_params[..., -2].unsqueeze(-1)\n",
    "    k2 = camera_params[..., -1].unsqueeze(-1)\n",
    "    \n",
    "    n = torch.sum(points_proj**2, axis=-1, keepdim=True)\n",
    "    r = 1 + k1 * n + k2 * n**2\n",
    "    points_proj = points_proj * r * f  # broadcasting will take care of the shape\n",
    "\n",
    "    return points_proj\n",
    "\n",
    "# dense version\n",
    "class ReprojNonBatched(nn.Module):\n",
    "    def __init__(self, camera_params, points_3d):\n",
    "        super().__init__()\n",
    "        self.pose = nn.Parameter(camera_params)\n",
    "        self.points_3d = nn.Parameter(points_3d)\n",
    "\n",
    "    def forward(self, points_2d, intr, camera_indices, point_indices):\n",
    "        camera_params = self.pose\n",
    "        points_3d = self.points_3d\n",
    "        if intr is not None:\n",
    "            camera_params = torch.cat([camera_params, intr], dim=-1)\n",
    "        points_proj = project(points_3d[point_indices], camera_params[camera_indices])\n",
    "        loss = points_proj - points_2d\n",
    "        return loss\n",
    "    \n",
    "    def get_num_params(self):\n",
    "        return self.pose.numel() + self.points_3d.numel()\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def least_square_error(camera_params, points_3d, camera_indices, point_indices, points_2d, intr=None):\n",
    "    model = ReprojNonBatched(camera_params, points_3d)\n",
    "    loss = model(points_2d, intr, camera_indices, point_indices)\n",
    "    return torch.sum(loss**2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def estimate_forward_flops_vmap():\n",
    "    \"\"\"\n",
    "    Estimate the number of FLOPs required for the forward pass of the model using vmap.\n",
    "    Because vmap is used, this is just the cost for a single point.\n",
    "\n",
    "    Returns:\n",
    "        total_flops: Estimated total number of FLOPs for the forward pass.\n",
    "    \"\"\"\n",
    "    flops_rotate_euler = 42 # 3 * 14; 14 ops per dimension\n",
    "    flops_translation = 3 # 1 op per dimension\n",
    "    flops_perspective = 4 # nagation and division for x and y (ditching z)\n",
    "    flops_n = 3 # n = torch.sum(points_proj**2, axis=-1, keepdim=True), each point has 2 elements now\n",
    "    flops_distortion = 4 # points_proj * r * f\n",
    "    flops_loss = 2 # 2 ops for loss computation\n",
    "\n",
    "    total_flops = (flops_rotate_euler + flops_translation + flops_perspective +\n",
    "                     flops_n + flops_distortion + flops_loss)\n",
    "    return total_flops\n",
    "\n",
    "def estimate_forward_flops(input_args):\n",
    "    \"\"\"\n",
    "    Estimate the number of FLOPs required for the forward pass of the model.\n",
    "\n",
    "    Args:\n",
    "        model: The model instance (e.g., ReprojNonBatched).\n",
    "        input_args: A tuple containing (points_2d, intr, camera_indices, point_indices).\n",
    "\n",
    "    Returns:\n",
    "        total_flops: Estimated total number of FLOPs for the forward pass.\n",
    "    \"\"\"\n",
    "    point_indices = input_args[\"point_indices\"]\n",
    "    N = point_indices.shape[0]\n",
    "\n",
    "    # there are N 3d points in each full forward pass\n",
    "    total_flops = N * estimate_forward_flops_vmap()\n",
    "\n",
    "    return total_flops\n",
    "\n",
    "\n",
    "def estimate_jacobian_flops(model, input_args, type=None):\n",
    "    \"\"\"\n",
    "    Estimate the number of FLOPs required for computing the Jacobian of the model.\n",
    "\n",
    "    Args:\n",
    "        model: The model instance (e.g., ReprojNonBatched).\n",
    "        input_args: A tuple containing (points_2d, intr, camera_indices, point_indices).\n",
    "\n",
    "    Returns:\n",
    "        total_flops: Estimated total number of FLOPs for Jacobian computation.\n",
    "    \"\"\"\n",
    "    point_indices = input_args[\"point_indices\"]\n",
    "\n",
    "    # this is the number of row in the Jacobian\n",
    "    N = point_indices.shape[0]\n",
    "\n",
    "    if type == 'pose':\n",
    "        M = model.model.pose.shape[0]\n",
    "    elif type == 'points':\n",
    "        M = model.model.points_3d.shape[0]\n",
    "\n",
    "    flops_backward = estimate_forward_flops_vmap() * 2 # assume backward pass is twice as expensive as forward pass\n",
    "\n",
    "    # In the dense mode, each jacobian row need to backward for *all* parameters\n",
    "    total_flops = N * M * flops_backward\n",
    "\n",
    "    return total_flops\n",
    "\n",
    "class DenseLMFlopsEstimator(pp.optim.LevenbergMarquardt):\n",
    "    @torch.no_grad()\n",
    "    def step(self, input_args, target=None, weight=None):\n",
    "        \"\"\"\n",
    "        Perform a Levenberg-Marquardt optimization step, estimating the FLOPs required.\n",
    "\n",
    "        Args:\n",
    "            input_args: A tuple containing (points_2d, intr, camera_indices, point_indices).\n",
    "            target: Not used in this context (optional).\n",
    "            weight: Weight matrix (optional).\n",
    "\n",
    "        Returns:\n",
    "            flops_dict (dict): A dictionary containing the estimated FLOPs for each step.\n",
    "        \"\"\"\n",
    "        point_indices = input_args[\"point_indices\"]\n",
    "\n",
    "        N = point_indices.shape[0] # Number of points\n",
    "        n = self.model.model.get_num_params() # Number of parameters\n",
    "\n",
    "        # model forward pass\n",
    "        flops_forward = estimate_forward_flops(input_args)\n",
    "\n",
    "        # Jacobian computation\n",
    "        flops_jacobian = estimate_jacobian_flops(self.model, input_args, type=\"pose\")\n",
    "        flops_jacobian += estimate_jacobian_flops(self.model, input_args, type=\"points\")\n",
    "\n",
    "        # negligible FLOPs for flattening Jacobian rows, correction applied to R and J, normalize R, W, and J, and transpose of Jacobian\n",
    "\n",
    "        # FLOPs for J_T @ J\n",
    "        # Jacobian dimension after flattening is J_T (n x N) and J (N x n)\n",
    "        # FLOPs for J_T @ J: n * n * (2N−1)\n",
    "        flops_JT_J = n * n * (2 * N - 1)\n",
    "\n",
    "        # FLOPs for adding damping to diagonal of A\n",
    "        # A is n x n\n",
    "        flops_damping = n  # one multiplication and addition per diagonal element\n",
    "\n",
    "        # FLOPs for computing b = -J_T @ R\n",
    "        # R has size N x 1, J_T is n x N\n",
    "        # FLOPs for J_T @ R: n * (2N−1)\n",
    "        flops_b = n * (2 * N - 1)\n",
    "\n",
    "        # Estimate FLOPs for solving linear system A delta = b\n",
    "        # A is n x n, b is n x 1\n",
    "        # choleskey decomposition takes 1/3 * n^3 flops\n",
    "        # back-substitution takes n^2 flops\n",
    "        flops_solver = (1/3) * n**3 + n**2\n",
    "\n",
    "        # Estimate FLOPs for updating parameters theta += delta\n",
    "        flops_param_update = n  # One addition per parameter\n",
    "\n",
    "        flops_dict = {\n",
    "            \"jac\": flops_jacobian,\n",
    "            \"solver\": flops_solver,\n",
    "            \"JT_J\": flops_JT_J,\n",
    "            \"others\": flops_forward + flops_damping + flops_b + flops_param_update,\n",
    "            \"total\": flops_jacobian + flops_solver + flops_forward + flops_JT_J + flops_damping + flops_b + flops_param_update\n",
    "        }\n",
    "    \n",
    "\n",
    "        # Return the total estimated FLOPs\n",
    "        return flops_dict\n",
    "\n",
    "def get_human_readable_flops(flops):\n",
    "    \"\"\"\n",
    "    Convert FLOPs to a human-readable format.\n",
    "\n",
    "    Args:\n",
    "        flops: Estimated FLOPs.\n",
    "\n",
    "    Returns:\n",
    "        human_readable_flops: FLOPs in a human-readable format.\n",
    "    \"\"\"\n",
    "\n",
    "    if flops < 1e3:\n",
    "        human_readable_flops = f\"{flops:.2f} FLOPs\"\n",
    "    elif flops < 1e6:\n",
    "        human_readable_flops = f\"{flops / 1e3:.2f} KFLOPs\"\n",
    "    elif flops < 1e9:\n",
    "        human_readable_flops = f\"{flops / 1e6:.2f} MFLOPs\"\n",
    "    elif flops < 1e12:\n",
    "        human_readable_flops = f\"{flops / 1e9:.2f} GFLOPs\"\n",
    "    elif flops < 1e15:\n",
    "        human_readable_flops = f\"{flops / 1e12:.2f} TFLOPs\"\n",
    "    else:\n",
    "        human_readable_flops = f\"{flops / 1e15:.2f} PFLOPs\"\n",
    "\n",
    "    \n",
    "\n",
    "    return human_readable_flops\n",
    "\n",
    "def get_human_readable_flops_dict(flops_dict):\n",
    "    \"\"\"\n",
    "    Convert FLOPs dictionary to a human-readable format.\n",
    "\n",
    "    Args:\n",
    "        flops_dict: Dictionary containing estimated FLOPs.\n",
    "\n",
    "    Returns:\n",
    "        human_readable_flops_dict: Dictionary containing estimated FLOPs in a human-readable format.\n",
    "    \"\"\"\n",
    "\n",
    "    human_readable_flops_dict = {\n",
    "        key: get_human_readable_flops(flops) for key, flops in flops_dict.items()\n",
    "    }\n",
    "\n",
    "    return human_readable_flops_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro_slam.sparse.py_ops import *\n",
    "from pyro_slam.sparse.bsr_cuda import *\n",
    "from pyro_slam.sparse.solve import *\n",
    "\n",
    "\n",
    "from torch.func import jacrev, jacfwd\n",
    "\n",
    "\n",
    "def construct_sbt(jac_from_vmap, num, index):\n",
    "    n = index.shape[0] # num 2D points\n",
    "    i = torch.stack([torch.arange(n).to(index.device), index])\n",
    "    block_shape = jac_from_vmap.shape[1:]\n",
    "    v = jac_from_vmap # adjust dimension to accomodate for sbt constructor\n",
    "    dummy_val = torch.arange(n, device=index.device, dtype=torch.int64)\n",
    "    dummy_coo = torch.sparse_coo_tensor(i, dummy_val, size=(n, num), device=index.device, dtype=torch.int64)\n",
    "    dummy_csc = dummy_coo.coalesce().to_sparse_csc()\n",
    "    return torch.sparse_bsc_tensor(ccol_indices = dummy_csc.ccol_indices(), \n",
    "                                   row_indices=dummy_csc.row_indices(),\n",
    "                                   values = v[dummy_csc.values()],\n",
    "                                   size = (n * block_shape[0], num * block_shape[1]),\n",
    "                                   device=index.device, dtype=DTYPE)\n",
    "\n",
    "def modjacrev_vmap(model, input, argnums=0, *, has_aux=False):\n",
    "    params = dict(model.named_parameters())\n",
    "\n",
    "    cameras_num = params['model.pose'].shape[0]\n",
    "    points_3d_num = params['model.points_3d'].shape[0]\n",
    "    # need to align the indices with the parameters\n",
    "    camera_indices = input['camera_indices']\n",
    "    point_indices = input['point_indices']\n",
    "    params['model.pose'] = params['model.pose'][camera_indices] # index using camera indices\n",
    "    params['model.points_3d'] = params['model.points_3d'][point_indices] # index using point indices\n",
    "    jac_points_3d, jac_pose = torch.vmap(jacrev(project, argnums=(0, 1), has_aux=has_aux))(params['model.points_3d'], params['model.pose'])\n",
    "    if USE_QUATERNIONS: \n",
    "        useful_idx = [0,1,2,3,4,5,7,8,9] if OPTIMIZE_INTRINSICS else [0,1,2,3,4,5,]\n",
    "        jac_pose = jac_pose[..., useful_idx] # remove the 4th element of the quaternion\n",
    "                                                    # because original is [qx, qy, qz, qw, tx, ty, tz], but always dqw = 0\n",
    "    return [construct_sbt(jac_pose, cameras_num, camera_indices), construct_sbt(jac_points_3d, points_3d_num, point_indices)]\n",
    "\n",
    "\n",
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "from torch import Tensor\n",
    "    \n",
    "class TrustRegion(pp.optim.strategy.TrustRegion):\n",
    "    def update(self, pg, last, loss, J, D, R, *args, **kwargs):\n",
    "        J = [i.to_sparse_coo() for i in J]\n",
    "        JD = None\n",
    "        for i in range(len(D)):\n",
    "            if JD is None:\n",
    "                JD = J[i] @ D[i]\n",
    "            else:\n",
    "                JD += J[i] @ D[i]\n",
    "        JD = JD[..., None]\n",
    "        quality = (last - loss) / -((JD).mT @ (2 * R.view_as(JD) + JD)).squeeze()\n",
    "        pg['radius'] = 1. / pg['damping']\n",
    "        if quality > pg['high']:\n",
    "            pg['radius'] = pg['up'] * pg['radius']\n",
    "            pg['down'] = self.down\n",
    "        elif quality > pg['low']:\n",
    "            pg['radius'] = pg['radius']\n",
    "            pg['down'] = self.down\n",
    "        else:\n",
    "            pg['radius'] = pg['radius'] * pg['down']\n",
    "            pg['down'] = pg['down'] * pg['factor']\n",
    "        pg['down'] = max(self.min, min(pg['down'], self.max))\n",
    "        pg['radius'] = max(self.min, min(pg['radius'], self.max))\n",
    "        pg['damping'] = 1. / pg['radius']\n",
    "\n",
    "class Adaptive(pp.optim.strategy.Adaptive):\n",
    "    def update(self, pg, last, loss, J, D, R, *args, **kwargs):\n",
    "        J = [i.to_sparse_coo() for i in J]\n",
    "        JD = None\n",
    "        for i in range(len(D)):\n",
    "            if JD is None:\n",
    "                JD = J[i] @ D[i]\n",
    "            else:\n",
    "                JD += J[i] @ D[i]\n",
    "        JD = JD[..., None]\n",
    "        quality = (last - loss) / -((JD).mT @ (2 * R.view_as(JD) + JD)).squeeze()\n",
    "        if quality > pg['high']:\n",
    "            pg['damping'] = pg['damping'] * pg['down']\n",
    "        elif quality > pg['low']:\n",
    "            pg['damping'] = pg['damping']\n",
    "        else:\n",
    "            pg['damping'] = pg['damping'] * pg['up']\n",
    "        pg['damping'] = max(self.min, min(pg['damping'], self.max))\n",
    "\n",
    "\n",
    "from pypose.optim.solver import CG\n",
    "class PCG(CG):\n",
    "    def __init__(self, maxiter=None, tol=0.00001):\n",
    "        super().__init__(maxiter, tol)\n",
    "    def forward(self, A: Tensor, b: Tensor, x: Tensor | None = None, M: Tensor | None = None) -> Tensor:\n",
    "        lhs = A\n",
    "        rhs = b\n",
    "        if b.dim() == 1:\n",
    "            b = b[..., None]\n",
    "        l_diag = lhs.diagonal()\n",
    "        l_diag[l_diag.abs() < 1e-6] = 1e-6\n",
    "        M = torch.sparse.spdiags(1 / l_diag[None].cpu(), offsets=torch.zeros(1, dtype=int), shape=lhs.shape)\n",
    "        M = M.to_sparse_bsr(blocksize=A.values().shape[-2:]).to(DEVICE)\n",
    "        rhs = M @ rhs\n",
    "        lhs = M @ lhs.to_sparse_bsc(blocksize=lhs.values().shape[-2:])\n",
    "\n",
    "        return super().forward(lhs, rhs, x)\n",
    "\n",
    "class SciPySpSolver(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "    def forward(self, A, b):\n",
    "        import scipy.sparse.linalg as spla\n",
    "        import scipy.sparse as sp\n",
    "        import numpy as np\n",
    "        if A.layout != torch.sparse_csr:\n",
    "            A = A.to_sparse_coo().to_sparse_csr()\n",
    "        A_csr = sp.csr_matrix((A.values().cpu().numpy(), \n",
    "                                   A.col_indices().cpu().numpy(),\n",
    "                                   A.crow_indices().cpu().numpy()),\n",
    "                                  shape=A.shape)\n",
    "        b = b.cpu().numpy()\n",
    "        x = spla.spsolve(A_csr, b, use_umfpack=False)\n",
    "        assert not np.isnan(x).any()\n",
    "        # a_err = np.linalg.norm(A_csr @ x - b)\n",
    "        # r_err = a_err / np.linalg.norm(b)\n",
    "        # print(f\"Linear Solver Error: {a_err}, relative error: {r_err}\")\n",
    "        return torch.from_numpy(x).to(A.device)\n",
    "\n",
    "from pyro_slam.sparse.solve import cusolvesp, cudss\n",
    "\n",
    "class cuSolverSP(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "    def forward(self, A, b):\n",
    "        x = cudss(A, b.flatten())\n",
    "        return x\n",
    "\n",
    "\n",
    "def estimate_sparse_jacobian_flops(input_args):\n",
    "    point_indices = input_args[\"point_indices\"]\n",
    "\n",
    "    # this is the number of row in the Jacobian\n",
    "    N = point_indices.shape[0]\n",
    "\n",
    "    # Estimate FLOPs for forward pass\n",
    "    flops_backward = estimate_forward_flops_vmap() * 2 # assume backward pass is twice as expensive as forward pass\n",
    "\n",
    "    # In the sparse mode, each jacobian row only need to backward for the parameters that affect the output\n",
    "    total_flops = N * flops_backward\n",
    "\n",
    "    return total_flops\n",
    "    \n",
    "def estimate_JT_J_flops(J: torch.Tensor) -> int:\n",
    "    # Get the row and column indices of the non-zeros\n",
    "    rows, cols = J._indices()\n",
    "\n",
    "    # Count how many non-zeros per column (this is efficient and avoids iteration)\n",
    "    col_nnz_counts = torch.bincount(cols)\n",
    "\n",
    "    # Compute FLOPs using vectorized operations\n",
    "    flops = torch.sum(col_nnz_counts ** 2).item()\n",
    "\n",
    "    return int(2 * flops)  # Multiply by 2 to account for multiplication and addition\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg as splinalg\n",
    "\n",
    "class SparseLMFlopsEstimator(pp.optim.LevenbergMarquardt):\n",
    "    @torch.no_grad()\n",
    "    def step(self, input, target=None, weight=None):\n",
    "        \n",
    "        flops_forward = 2 * estimate_forward_flops(input)\n",
    "        flops_jacobian = 2 * estimate_sparse_jacobian_flops(input) # two jacobians\n",
    "        flops_param_update = self.model.model.get_num_params() # number of parameters\n",
    "        \n",
    "        # TBD by actual data\n",
    "        flops_JT_J = 0\n",
    "        flops_damping = 0\n",
    "        flops_b = 0\n",
    "        flops_solver = 0\n",
    "        \n",
    "        for pg in self.param_groups:\n",
    "            weight = self.weight if weight is None else weight\n",
    "            R = list(self.model(input))\n",
    "            J = modjacrev_vmap(self.model, input)\n",
    "\n",
    "            R = R[0]\n",
    "            J = torch.cat([j.to_sparse_coo() for j in J], dim=-1)\n",
    "\n",
    "            self.last = self.loss = self.loss if hasattr(self, 'loss') \\\n",
    "                                    else self.model.loss(input, target)\n",
    "            \n",
    "            J_T = J.T @ weight if weight is not None else J.T\n",
    "            \n",
    "            A, self.reject_count = J_T @ J, 0\n",
    "            flops_JT_J += estimate_JT_J_flops(J)\n",
    "            \n",
    "            A = A.to_sparse_csr()\n",
    "            diagonal_op_(A, op=partial(torch.clamp_, min=pg['min'], max=pg['max']))\n",
    "            flops_damping += A.size(0) # diagonal\n",
    "\n",
    "            while self.last <= self.loss:\n",
    "                diagonal_op_(A, op=partial(torch.mul, other=1+pg['damping']))\n",
    "                try:\n",
    "                    D = self.solver(A = A, b = -J_T @ R.view(-1, 1))\n",
    "                    flops_b += J_T._nnz() * 2\n",
    "                    num_nonzeros_L = A._nnz() * 2  # The non-zeros in the factor L\n",
    "                    flops_factorization = 6 * num_nonzeros_L\n",
    "                    flops_substitution = 2 * num_nonzeros_L\n",
    "                    flops_solver += flops_factorization + flops_substitution\n",
    "                    D = D[:, None]\n",
    "                except Exception as e:\n",
    "                    print(e, \"\\nLinear solver failed. Breaking optimization step...\")\n",
    "                    break\n",
    "                self.update_parameter(pg['params'], D)\n",
    "                self.loss = self.model.loss(input, target)\n",
    "                print(\"Loss:\", self.loss, \"Last Loss:\", self.last, \"Reject Count:\", self.reject_count, \"Damping:\", pg['damping'])\n",
    "                self.strategy.update(pg, last=self.last, loss=self.loss, J=J, D=D, R=R.view(-1, 1))\n",
    "                if self.last < self.loss and self.reject_count < self.reject: # reject step\n",
    "                    self.update_parameter(params = pg['params'], step = -D)\n",
    "                    self.loss, self.reject_count = self.last, self.reject_count + 1\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        flops_dict = {\n",
    "            \"jac\": flops_jacobian,\n",
    "            \"solver\": flops_solver,\n",
    "            \"JT_J\": flops_JT_J,\n",
    "            \"others\": flops_forward + flops_damping + flops_b + flops_param_update,\n",
    "            \"total\": flops_jacobian + flops_solver + flops_forward + flops_JT_J + flops_damping + flops_b + flops_param_update\n",
    "        }\n",
    "        return flops_dict\n",
    "    def update_parameter(self, params, step):\n",
    "        numels = []\n",
    "        for i, p in enumerate(params):\n",
    "            if p.requires_grad:\n",
    "                if i == 0:\n",
    "                    numels.append(p.shape[0] * (9 if OPTIMIZE_INTRINSICS else 6))\n",
    "                else:\n",
    "                    numels.append(p.numel())\n",
    "        steps = step.split(numels)\n",
    "        for i, (p, d) in enumerate(zip(params, steps)):\n",
    "            if p.requires_grad:\n",
    "                if i == 0:\n",
    "                    # continue\n",
    "                    if USE_QUATERNIONS:\n",
    "                        p[..., :7] = pp.SE3(p[..., :7]).add_(pp.se3(d.view(p.shape[0], -1)[..., :6]))\n",
    "                        if OPTIMIZE_INTRINSICS: p[:, 7:] += d.view(p.shape[0], -1)[:, 6:]\n",
    "                        continue\n",
    "                p.add_(d.view(p.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss: 85279364.20754541\n",
      "called_count: 4\n",
      "Fill-in factor: 0.19957\n",
      "Loss: tensor(4.8047e+106, device='cuda:0') Last Loss: tensor(1.7056e+08, device='cuda:0') Reject Count: 0 Damping: 0.0001\n",
      "FLOPs for step 1: {'jac': '157.46 MFLOPs', 'solver': '414.47 MFLOPs', 'JT_J': '16.17 GFLOPs', 'others': '104.13 MFLOPs', 'total': '16.85 GFLOPs'}\n",
      "Ending loss: 2.402367371033183e+106\n"
     ]
    }
   ],
   "source": [
    "from pypose.optim.solver import CG\n",
    "from pypose.optim import LevenbergMarquardt\n",
    "\n",
    "camera_params_other = None if NUM_CAMERA_PARAMS == trimmed_dataset['camera_params'].shape[1] else trimmed_dataset['camera_params'][:, NUM_CAMERA_PARAMS:]\n",
    "input = {\"points_2d\": trimmed_dataset['points_2d'],\n",
    "         \"intr\": camera_params_other,\n",
    "         \"camera_indices\": trimmed_dataset['camera_index_of_observations'],\n",
    "         \"point_indices\": trimmed_dataset['point_index_of_observations']}\n",
    "\n",
    "model_non_batched = ReprojNonBatched(trimmed_dataset['camera_params'][:, :NUM_CAMERA_PARAMS].clone(),\n",
    "                                     trimmed_dataset['points_3d'].clone())\n",
    "model_non_batched = model_non_batched.to(DEVICE)\n",
    "\n",
    "strategy = pp.optim.strategy.Adaptive(damping=0.0001, min=1.5e-6)\n",
    "\n",
    "#optimizer_flops_estimator = DenseLMFlopsEstimator(model_non_batched, strategy=strategy, reject=30)\n",
    "sparse_solver = cuSolverSP()\n",
    "optimizer_flops_estimator = SparseLMFlopsEstimator(model_non_batched, strategy=strategy, solver=sparse_solver, reject=0)\n",
    "\n",
    "print('Starting loss:', least_square_error(model_non_batched.pose, model_non_batched.points_3d, trimmed_dataset['camera_index_of_observations'], trimmed_dataset['point_index_of_observations'], trimmed_dataset['points_2d'], intr=camera_params_other).item())\n",
    "for idx in range(1):\n",
    "    flops_dict = optimizer_flops_estimator.step(input)\n",
    "    print(f\"FLOPs for step {idx + 1}: {get_human_readable_flops_dict(flops_dict)}\")\n",
    "    #print('Loss:', least_square_error(model_non_batched.pose, model_non_batched.points_3d, trimmed_dataset['camera_index_of_observations'], trimmed_dataset['point_index_of_observations'], trimmed_dataset['points_2d'], intr=camera_params_other).item())\n",
    "print('Ending loss:', least_square_error(model_non_batched.pose, model_non_batched.points_3d, trimmed_dataset['camera_index_of_observations'], trimmed_dataset['point_index_of_observations'], trimmed_dataset['points_2d'], intr=camera_params_other).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
