{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W726 21:21:50.308701495 OperatorEntry.cpp:153] Warning: Warning only once for all operators,  other operators may also be overrided.\n",
      "  Overriding a previously registered kernel for the same operator and the same dispatch key\n",
      "  operator: aten::mm(Tensor self, Tensor mat2) -> Tensor\n",
      "    registered at /home/zitongzhan/base/pytorch/build/aten/src/ATen/RegisterSchema.cpp:6\n",
      "  dispatch key: SparseCsrCPU\n",
      "  previous kernel: registered at /home/zitongzhan/base/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1079\n",
      "       new kernel: registered at /media/zitongzhan/New_Volume/pyro_slam/pyro_slam/sparse/sparse_op_cpp.cpp:206 (function operator())\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import warnings\n",
    "from typing import Callable, List, Optional\n",
    "from torch.library import Library\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "# diag is already mature \n",
    "from pyro_slam.sparse.py_ops import *\n",
    "from pyro_slam.sparse.bsr_cuda import *\n",
    "from pyro_slam.sparse.solve import *\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5RoSZ7kJg-W3"
   },
   "source": [
    "# Bundle Adjustment Example using SparsePyBA and the BAL dataset\n",
    "\n",
    "```\n",
    "The dataset is from the following paper:  \n",
    "Sameer Agarwal, Noah Snavely, Steven M. Seitz, and Richard Szeliski.  \n",
    "Bundle adjustment in the large.  \n",
    "In European Conference on Computer Vision (ECCV), 2010.  \n",
    "```\n",
    "\n",
    "Link to the dataset: https://grail.cs.washington.edu/projects/bal/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming data for ladybug...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/zitongzhan/New_Volume/pyro_slam/pypose/lietensor/lietensor.py:918: UserWarning: Tensor Shape Invalid by calling <built-in method cat of type object at 0xffff82244370>, go to https://pypose.org/docs/main/generated/pypose.LieTensor\n",
      "  warnings.warn('Tensor Shape Invalid by calling {}, ' \\\n",
      "/media/zitongzhan/New_Volume/pyro_slam/datapipes/bal_loader.py:164: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  camera_params = torch.tensor(camera_params).to(torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched problem-49-7776-pre from ladybug\n"
     ]
    }
   ],
   "source": [
    "from datapipes.bal_loader import get_problem, read_bal_data\n",
    "\n",
    "TARGET_DATASET = \"ladybug\"\n",
    "TARGET_PROBLEM = \"problem-49-7776-pre\"\n",
    "# TARGET_PROBLEM = \"problem-1723-156502-pre\"\n",
    "# TARGET_PROBLEM = \"problem-1695-155710-pre\"  \n",
    "# TARGET_PROBLEM = \"problem-969-105826-pre\"\n",
    "\n",
    "\n",
    "# TARGET_DATASET = \"trafalgar\"\n",
    "# TARGET_PROBLEM = \"problem-21-11315-pre\"\n",
    "\n",
    "DEVICE = 'cuda' # change device to CPU if needed\n",
    "DTYPE = torch.float64\n",
    "USE_QUATERNIONS = True\n",
    "OPTIMIZE_INTRINSICS = True\n",
    "# dataset = read_bal_data(file_name='Data/dubrovnik-3-7-pre.txt', use_quat=USE_QUATERNIONS)\n",
    "dataset = get_problem(TARGET_PROBLEM, TARGET_DATASET, use_quat=USE_QUATERNIONS)\n",
    "\n",
    "if OPTIMIZE_INTRINSICS:\n",
    "    NUM_CAMERA_PARAMS = 10 if USE_QUATERNIONS else 9\n",
    "else:\n",
    "    NUM_CAMERA_PARAMS = 7 if USE_QUATERNIONS else 6\n",
    "\n",
    "print(f'Fetched {TARGET_PROBLEM} from {TARGET_DATASET}')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pypose as pp\n",
    "\n",
    "trimmed_dataset = dataset\n",
    "trimmed_dataset = {k: v.to(DEVICE) for k, v in trimmed_dataset.items() if type(v) == torch.Tensor}\n",
    "\n",
    "def convert_to(type):\n",
    "    for k, v in trimmed_dataset.items():\n",
    "        if 'index' not in k:\n",
    "            trimmed_dataset[k] = v.to(type)\n",
    "\n",
    "\n",
    "convert_to(DTYPE)\n",
    "torch.set_default_dtype(DTYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def rotate_euler(points, rot_vecs):\n",
    "    \"\"\"Rotate points by given rotation vectors.\n",
    "\n",
    "    Rodrigues' rotation formula is used.\n",
    "    \"\"\"\n",
    "    theta = torch.norm(rot_vecs, dim=-1, keepdim=True)\n",
    "    v = torch.nan_to_num(rot_vecs / theta)\n",
    "    dot = torch.sum(points * v, dim=-1, keepdim=True)\n",
    "    cos_theta = torch.cos(theta)\n",
    "    sin_theta = torch.sin(theta)\n",
    "    return cos_theta * points + sin_theta * torch.cross(v, points, dim=-1) + dot * (1 - cos_theta) * v\n",
    "\n",
    "def rotate_quat(points, rot_vecs):\n",
    "    rot_vecs = pp.SE3(rot_vecs)\n",
    "    return rot_vecs.Act(points)\n",
    "\n",
    "def project(points, camera_params):\n",
    "    \"\"\"Convert 3-D points to 2-D by projecting onto images.\"\"\"\n",
    "    if USE_QUATERNIONS:\n",
    "        points_proj = rotate_quat(points, camera_params[..., :7])\n",
    "    else:\n",
    "        points_proj = rotate_euler(points, camera_params[..., 3:6])\n",
    "        points_proj = points_proj + camera_params[..., :3]\n",
    "    points_proj = -points_proj[..., :2] / points_proj[..., 2].unsqueeze(-1)  # add dimension for broadcasting\n",
    "    f = camera_params[..., -3].unsqueeze(-1)\n",
    "    k1 = camera_params[..., -2].unsqueeze(-1)\n",
    "    k2 = camera_params[..., -1].unsqueeze(-1)\n",
    "    \n",
    "    n = torch.sum(points_proj**2, axis=-1, keepdim=True)\n",
    "    r = 1 + k1 * n + k2 * n**2\n",
    "    points_proj = points_proj * r * f  # broadcasting will take care of the shape\n",
    "\n",
    "    return points_proj\n",
    "\n",
    "\n",
    "# sparse version\n",
    "class ReprojNonBatched(nn.Module):\n",
    "    def __init__(self, camera_params, points_3d):\n",
    "        super().__init__()\n",
    "        self.pose = nn.Parameter(camera_params)\n",
    "        self.points_3d = nn.Parameter(points_3d)\n",
    "\n",
    "    def forward(self, points_2d, intr, camera_indices, point_indices):\n",
    "        camera_params = self.pose\n",
    "        points_3d = self.points_3d\n",
    "        if intr is not None:\n",
    "            camera_params = torch.cat([camera_params, intr], dim=-1)\n",
    "        points_proj = project(points_3d[point_indices], camera_params[camera_indices])\n",
    "        loss = points_proj - points_2d\n",
    "        return loss\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "def least_square_error(camera_params, points_3d, camera_indices, point_indices, points_2d, intr=None):\n",
    "    model = ReprojNonBatched(camera_params, points_3d)\n",
    "    loss = model(points_2d, intr, camera_indices, point_indices)\n",
    "    return torch.sum(loss**2) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import jacrev, jacfwd\n",
    "\n",
    "\n",
    "def construct_sbt(jac_from_vmap, num, index):\n",
    "    n = index.shape[0] # num 2D points\n",
    "    i = torch.stack([torch.arange(n).to(index.device), index])\n",
    "    block_shape = jac_from_vmap.shape[1:]\n",
    "    v = jac_from_vmap # adjust dimension to accomodate for sbt constructor\n",
    "    dummy_val = torch.arange(n, device=index.device, dtype=torch.int64)\n",
    "    dummy_coo = torch.sparse_coo_tensor(i, dummy_val, size=(n, num), device=index.device, dtype=torch.int64)\n",
    "    dummy_csc = dummy_coo.coalesce().to_sparse_csc()\n",
    "    return torch.sparse_bsc_tensor(ccol_indices = dummy_csc.ccol_indices(), \n",
    "                                   row_indices=dummy_csc.row_indices(),\n",
    "                                   values = v[dummy_csc.values()],\n",
    "                                   size = (n * block_shape[0], num * block_shape[1]),\n",
    "                                   device=index.device, dtype=DTYPE)\n",
    "\n",
    "def modjacrev_vmap(model, input, argnums=0, *, has_aux=False):\n",
    "    params = dict(model.named_parameters())\n",
    "\n",
    "    cameras_num = params['model.pose'].shape[0]\n",
    "    points_3d_num = params['model.points_3d'].shape[0]\n",
    "    # need to align the indices with the parameters\n",
    "    camera_indices = input['camera_indices']\n",
    "    point_indices = input['point_indices']\n",
    "    params['model.pose'] = params['model.pose'][camera_indices] # index using camera indices\n",
    "    params['model.points_3d'] = params['model.points_3d'][point_indices] # index using point indices\n",
    "    jac_points_3d, jac_pose = torch.vmap(jacrev(project, argnums=(0, 1), has_aux=has_aux))(params['model.points_3d'], params['model.pose'])\n",
    "    if USE_QUATERNIONS: \n",
    "        useful_idx = [0,1,2,3,4,5,7,8,9] if OPTIMIZE_INTRINSICS else [0,1,2,3,4,5,]\n",
    "        jac_pose = jac_pose[..., useful_idx] # remove the 4th element of the quaternion\n",
    "                                                    # because original is [qx, qy, qz, qw, tx, ty, tz], but always dqw = 0\n",
    "    return [construct_sbt(jac_pose, cameras_num, camera_indices), construct_sbt(jac_points_3d, points_3d_num, point_indices)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Optional\n",
    "\n",
    "from torch import Tensor\n",
    "    \n",
    "class TrustRegion(pp.optim.strategy.TrustRegion):\n",
    "    def update(self, pg, last, loss, J, D, R, *args, **kwargs):\n",
    "        J = [i.to_sparse_coo() for i in J]\n",
    "        JD = None\n",
    "        for i in range(len(D)):\n",
    "            if JD is None:\n",
    "                JD = J[i] @ D[i]\n",
    "            else:\n",
    "                JD += J[i] @ D[i]\n",
    "        JD = JD[..., None]\n",
    "        quality = (last - loss) / -((JD).mT @ (2 * R.view_as(JD) + JD)).squeeze()\n",
    "        pg['radius'] = 1. / pg['damping']\n",
    "        if quality > pg['high']:\n",
    "            pg['radius'] = pg['up'] * pg['radius']\n",
    "            pg['down'] = self.down\n",
    "        elif quality > pg['low']:\n",
    "            pg['radius'] = pg['radius']\n",
    "            pg['down'] = self.down\n",
    "        else:\n",
    "            pg['radius'] = pg['radius'] * pg['down']\n",
    "            pg['down'] = pg['down'] * pg['factor']\n",
    "        pg['down'] = max(self.min, min(pg['down'], self.max))\n",
    "        pg['radius'] = max(self.min, min(pg['radius'], self.max))\n",
    "        pg['damping'] = 1. / pg['radius']\n",
    "\n",
    "class Adaptive(pp.optim.strategy.Adaptive):\n",
    "    def update(self, pg, last, loss, J, D, R, *args, **kwargs):\n",
    "        J = [i.to_sparse_coo() for i in J]\n",
    "        JD = None\n",
    "        for i in range(len(D)):\n",
    "            if JD is None:\n",
    "                JD = J[i] @ D[i]\n",
    "            else:\n",
    "                JD += J[i] @ D[i]\n",
    "        JD = JD[..., None]\n",
    "        quality = (last - loss) / -((JD).mT @ (2 * R.view_as(JD) + JD)).squeeze()\n",
    "        if quality > pg['high']:\n",
    "            pg['damping'] = pg['damping'] * pg['down']\n",
    "        elif quality > pg['low']:\n",
    "            pg['damping'] = pg['damping']\n",
    "        else:\n",
    "            pg['damping'] = pg['damping'] * pg['up']\n",
    "        pg['damping'] = max(self.min, min(pg['damping'], self.max))\n",
    "\n",
    "\n",
    "from pypose.optim.solver import CG\n",
    "class PCG(CG):\n",
    "    def __init__(self, maxiter=None, tol=0.00001):\n",
    "        super().__init__(maxiter, tol)\n",
    "    def forward(self, A: Tensor, b: Tensor, x: Tensor | None = None, M: Tensor | None = None) -> Tensor:\n",
    "        lhs = A\n",
    "        rhs = b\n",
    "        if b.dim() == 1:\n",
    "            b = b[..., None]\n",
    "        l_diag = lhs.diagonal()\n",
    "        l_diag[l_diag.abs() < 1e-6] = 1e-6\n",
    "        M = torch.sparse.spdiags(1 / l_diag[None].cpu(), offsets=torch.zeros(1, dtype=int), shape=lhs.shape)\n",
    "        M = M.to_sparse_bsr(blocksize=A.values().shape[-2:]).to(DEVICE)\n",
    "        rhs = M @ rhs\n",
    "        lhs = M @ lhs.to_sparse_bsc(blocksize=lhs.values().shape[-2:])\n",
    "\n",
    "        return super().forward(lhs, rhs, x)\n",
    "\n",
    "class SciPySpSolver(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "    def forward(self, A, b):\n",
    "        import scipy.sparse.linalg as spla\n",
    "        import scipy.sparse as sp\n",
    "        import numpy as np\n",
    "        if A.layout != torch.sparse_csr:\n",
    "            A = A.to_sparse_coo().to_sparse_csr()\n",
    "        A_csr = sp.csr_matrix((A.values().cpu().numpy(), \n",
    "                                   A.col_indices().cpu().numpy(),\n",
    "                                   A.crow_indices().cpu().numpy()),\n",
    "                                  shape=A.shape)\n",
    "        b = b.cpu().numpy()\n",
    "        x = spla.spsolve(A_csr, b, use_umfpack=False)\n",
    "        assert not np.isnan(x).any()\n",
    "        # a_err = np.linalg.norm(A_csr @ x - b)\n",
    "        # r_err = a_err / np.linalg.norm(b)\n",
    "        # print(f\"Linear Solver Error: {a_err}, relative error: {r_err}\")\n",
    "        return torch.from_numpy(x).to(A.device)\n",
    "\n",
    "from pyro_slam.sparse.solve import cusolvesp, cudss\n",
    "\n",
    "class cuSolverSP(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "    def forward(self, A, b):\n",
    "        x = cudss(A, b.flatten())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM(pp.optim.LevenbergMarquardt):\n",
    "    @torch.no_grad()\n",
    "    def step(self, input, target=None, weight=None):\n",
    "        for pg in self.param_groups:\n",
    "            weight = self.weight if weight is None else weight\n",
    "            R = list(self.model(input))\n",
    "            J = modjacrev_vmap(self.model, input)\n",
    "\n",
    "            # params = dict(self.model.named_parameters())\n",
    "            # params_values = tuple(params.values())\n",
    "            # J = [self.model.flatten_row_jacobian(Jr, params_values) for Jr in J]\n",
    "            # for i in range(len(R)):\n",
    "            #     R[i], J[i] = self.corrector[0](R = R[i], J = J[i]) if len(self.corrector) ==1 \\\n",
    "            #         else self.corrector[i](R = R[i], J = J[i])\n",
    "            R = R[0]\n",
    "            J = torch.cat([j.to_sparse_coo() for j in J], dim=-1)\n",
    "\n",
    "            self.last = self.loss = self.loss if hasattr(self, 'loss') \\\n",
    "                                    else self.model.loss(input, target)\n",
    "            J_T = J.T @ weight if weight is not None else J.T\n",
    "            A, self.reject_count = J_T @ J, 0\n",
    "            # A = A.to_sparse_bsr(blocksize=(1,1))\n",
    "            A = A.to_sparse_csr()\n",
    "            diagonal_op_(A, op=partial(torch.clamp_, min=pg['min'], max=pg['max']))\n",
    "\n",
    "            while self.last <= self.loss:\n",
    "                diagonal_op_(A, op=partial(torch.mul, other=1+pg['damping']))\n",
    "                try:\n",
    "                    D = self.solver(A = A, b = -J_T @ R.view(-1, 1))\n",
    "                    D = D[:, None]\n",
    "                except Exception as e:\n",
    "                    print(e, \"\\nLinear solver failed. Breaking optimization step...\")\n",
    "                    break\n",
    "                self.update_parameter(pg['params'], D)\n",
    "                self.loss = self.model.loss(input, target)\n",
    "                print(\"Loss:\", self.loss, \"Last Loss:\", self.last, \"Reject Count:\", self.reject_count, \"Damping:\", pg['damping'])\n",
    "                self.strategy.update(pg, last=self.last, loss=self.loss, J=J, D=D, R=R.view(-1, 1))\n",
    "                if self.last < self.loss and self.reject_count < self.reject: # reject step\n",
    "                    self.update_parameter(params = pg['params'], step = -D)\n",
    "                    self.loss, self.reject_count = self.last, self.reject_count + 1\n",
    "                else:\n",
    "                    break\n",
    "        return self.loss\n",
    "    def update_parameter(self, params, step):\n",
    "        numels = []\n",
    "        for i, p in enumerate(params):\n",
    "            if p.requires_grad:\n",
    "                if i == 0:\n",
    "                    numels.append(p.shape[0] * (9 if OPTIMIZE_INTRINSICS else 6))\n",
    "                else:\n",
    "                    numels.append(p.numel())\n",
    "        steps = step.split(numels)\n",
    "        for i, (p, d) in enumerate(zip(params, steps)):\n",
    "            if p.requires_grad:\n",
    "                if i == 0:\n",
    "                    # continue\n",
    "                    if USE_QUATERNIONS:\n",
    "                        p[..., :7] = pp.SE3(p[..., :7]).add_(pp.se3(d.view(p.shape[0], -1)[..., :6]))\n",
    "                        if OPTIMIZE_INTRINSICS: p[:, 7:] += d.view(p.shape[0], -1)[:, 6:]\n",
    "                        continue\n",
    "                p.add_(d.view(p.shape))\n",
    "\n",
    "\n",
    "class Schur(LM):\n",
    "    @torch.no_grad()\n",
    "    def step(self, input, target=None, weight=None):\n",
    "        for pg in self.param_groups:\n",
    "            weight = self.weight if weight is None else weight\n",
    "            R = self.model(input, target)\n",
    "            J = modjacrev_vmap(self.model, input)\n",
    "\n",
    "            R = R[0]\n",
    "            J[0] = J[0]\n",
    "            J[1] = J[1]\n",
    "\n",
    "            self.last = self.loss = self.loss if hasattr(self, 'loss') \\\n",
    "                                    else self.model.loss(input, target)\n",
    "            torch.cuda.nvtx.range_push(\"JTJc\")\n",
    "            U = J[0].mT @ J[0]\n",
    "            torch.cuda.nvtx.range_pop()\n",
    "            # J0D = J[0].to_dense()\n",
    "            # UD = U.to_dense()\n",
    "            # torch.testing.assert_close(UD, J0D.mT @ J0D)\n",
    "            # del J0D\n",
    "            # del UD\n",
    "            torch.cuda.nvtx.range_push(\"JTJp\")\n",
    "            V = J[1].mT @ J[1]\n",
    "            torch.cuda.nvtx.range_pop()\n",
    "            # J1D = J[1].to_dense()\n",
    "            # VD = V.to_dense()\n",
    "            # torch.testing.assert_close(VD, J1D.mT @ J1D)\n",
    "            # del J1D\n",
    "            # del VD\n",
    "            \n",
    "            torch.cuda.nvtx.range_push(\"Clamp\")\n",
    "            diagonal_op_(U, op=partial(torch.clamp_, min=pg['min'], max=pg['max']))\n",
    "            diagonal_op_(V, op=partial(torch.clamp_, min=pg['min'], max=pg['max']))\n",
    "            torch.cuda.nvtx.range_pop()\n",
    "\n",
    "            while self.last <= self.loss:\n",
    "                damping = pg['damping']\n",
    "                R = R.reshape(-1)\n",
    "                \n",
    "                torch.cuda.nvtx.range_push(\"Damp\")\n",
    "                diagonal_op_(U, op=partial(torch.add, other=(torch.diagonal(U).pow(2)) * damping))\n",
    "                diagonal_op_(V, op=partial(torch.add, other=(torch.diagonal(V).pow(2)) * damping))\n",
    "                torch.cuda.nvtx.range_pop()\n",
    "\n",
    "                torch.cuda.nvtx.range_push(\"W\")\n",
    "                W = J[0].mT @ J[1]\n",
    "                torch.cuda.nvtx.range_pop()\n",
    "                torch.cuda.nvtx.range_push(\"Ic\")\n",
    "                Ic = -J[0].mT.to_sparse_coo().to_sparse_csr() @ R\n",
    "                Ip = -J[1].mT.to_sparse_coo().to_sparse_csr() @ R\n",
    "                torch.cuda.nvtx.range_pop()\n",
    "                torch.cuda.nvtx.range_push(\"Inv\")\n",
    "                V_i = inv_op(V)\n",
    "                torch.cuda.nvtx.range_pop()\n",
    "                torch.cuda.nvtx.range_push(\"WVi\")\n",
    "                WV_i = W @ V_i\n",
    "                torch.cuda.nvtx.range_pop()\n",
    "                torch.cuda.nvtx.range_push(\"rhs1\")\n",
    "                rhs = Ic - WV_i.to_sparse_coo().to_sparse_csr() @ Ip  \n",
    "                torch.cuda.nvtx.range_pop()\n",
    "                torch.cuda.nvtx.range_push(\"lhs1\")\n",
    "                lhs = add_op(U, (-WV_i @ W.mT))  # this matrix is NOT symetric\n",
    "                torch.cuda.nvtx.range_pop()\n",
    "\n",
    "                torch.cuda.nvtx.range_push(\"Solve C\")\n",
    "                try:\n",
    "                    D_c = self.solver(A = lhs.to_sparse_coo().to_sparse_csr(), b = rhs)\n",
    "                except Exception as e:\n",
    "                    print(e, \"\\nLinear solver failed. Breaking optimization step...\")\n",
    "                    break\n",
    "                torch.cuda.nvtx.range_pop()\n",
    "                \n",
    "                torch.cuda.nvtx.range_push(\"rhs2\")\n",
    "                rhs = Ip - W.mT.to_sparse_coo() @ D_c\n",
    "                torch.cuda.nvtx.range_pop()\n",
    "                torch.cuda.nvtx.range_push(\"solve2\")\n",
    "                lhs = V\n",
    "                D_p = self.solver(A = lhs.to_sparse_coo().to_sparse_csr(), b = rhs)\n",
    "                torch.cuda.nvtx.range_pop()\n",
    "                torch.cuda.nvtx.range_push(\"Update\")\n",
    "                D = torch.cat([D_c, D_p])\n",
    "                self.update_parameter(pg['params'], D)\n",
    "                torch.cuda.nvtx.range_pop()\n",
    "                self.loss = self.model.loss(input, target)\n",
    "                print(\"Loss:\", self.loss, \"Last Loss:\", self.last, \"Reject Count:\", self.reject_count, \"Damping:\", pg['damping'])\n",
    "                torch.cuda.nvtx.range_push(\"Strategy\")\n",
    "                self.strategy.update(pg, last=self.last, loss=self.loss, J=J, D=[D_c, D_p], R=R.view(-1, 1))\n",
    "                torch.cuda.nvtx.range_pop()\n",
    "                if self.last < self.loss and self.reject_count < self.reject: # reject step\n",
    "                    self.update_parameter(params = pg['params'], step = -D)\n",
    "                    self.loss, self.reject_count = self.last, self.reject_count + 1\n",
    "                else:\n",
    "                    break\n",
    "        return self.loss\n",
    "    \n",
    "    # def _update_parameter(self, params, step):\n",
    "        \n",
    "    #     V, Ip, W = self.model.cur['V'], self.model.cur['Ip'], self.model.cur['W']\n",
    "    #     rhs = Ip - W.mT.to_sparse_coo() @ step\n",
    "    #     lhs = V\n",
    "    #     D_p = self.solver(A = lhs, b = rhs)\n",
    "    #     params[1] += D_p.view_as(params[1])\n",
    "    #     return step, D_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss: 850912.7770917793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1298831/2838689061.py:11: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /home/zitongzhan/base/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  dummy_csc = dummy_coo.coalesce().to_sparse_csc()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called_count: 0\n",
      "Loss: tensor(91744.2051, device='cuda:0') Last Loss: tensor(1701825.5542, device='cuda:0') Reject Count: 0 Damping: 0.0001\n",
      "Time 2.229585693359375\n",
      "Loss: 45872.10257305857\n",
      "called_count: 1\n",
      "Loss: tensor(29565.0478, device='cuda:0') Last Loss: tensor(91744.2051, device='cuda:0') Reject Count: 0 Damping: 5e-05\n",
      "Time 0.1874469757080078\n",
      "Loss: 14782.523915175754\n",
      "called_count: 2\n",
      "Loss: tensor(26947.8921, device='cuda:0') Last Loss: tensor(29565.0478, device='cuda:0') Reject Count: 0 Damping: 2.5e-05\n",
      "Time 0.18658268737792968\n",
      "Loss: 13473.946054467091\n",
      "called_count: 3\n",
      "Loss: tensor(26843.7234, device='cuda:0') Last Loss: tensor(26947.8921, device='cuda:0') Reject Count: 0 Damping: 1.25e-05\n",
      "Time 0.17814694213867188\n",
      "Loss: 13421.861690113663\n",
      "called_count: 4\n",
      "Loss: tensor(26815.0757, device='cuda:0') Last Loss: tensor(26843.7234, device='cuda:0') Reject Count: 0 Damping: 6.25e-06\n",
      "Time 0.17733056640625\n",
      "Loss: 13407.537843024096\n",
      "called_count: 5\n",
      "Loss: tensor(26820.8826, device='cuda:0') Last Loss: tensor(26815.0757, device='cuda:0') Reject Count: 0 Damping: 3.125e-06\n",
      "called_count: 6\n",
      "Loss: tensor(26787.5292, device='cuda:0') Last Loss: tensor(26815.0757, device='cuda:0') Reject Count: 1 Damping: 6.25e-06\n",
      "Time 0.29180194091796874\n",
      "Loss: 13393.764576455946\n",
      "called_count: 7\n",
      "Loss: tensor(26787.8570, device='cuda:0') Last Loss: tensor(26787.5292, device='cuda:0') Reject Count: 0 Damping: 3.125e-06\n",
      "called_count: 8\n",
      "Loss: tensor(26774.4932, device='cuda:0') Last Loss: tensor(26787.5292, device='cuda:0') Reject Count: 1 Damping: 6.25e-06\n",
      "Time 0.28043524169921874\n",
      "Loss: 13387.24658648103\n",
      "called_count: 9\n",
      "Loss: tensor(26768.1235, device='cuda:0') Last Loss: tensor(26774.4932, device='cuda:0') Reject Count: 0 Damping: 3.125e-06\n",
      "Time 0.18740489196777343\n",
      "Loss: 13384.061742723745\n",
      "called_count: 10\n",
      "Loss: tensor(26739.9793, device='cuda:0') Last Loss: tensor(26768.1235, device='cuda:0') Reject Count: 0 Damping: 3.125e-06\n",
      "Time 0.16896809387207032\n",
      "Loss: 13369.98965671571\n",
      "called_count: 11\n",
      "Loss: tensor(26736.7629, device='cuda:0') Last Loss: tensor(26739.9793, device='cuda:0') Reject Count: 0 Damping: 1.5625e-06\n",
      "Time 0.17559356689453126\n",
      "Loss: 13368.381464217244\n",
      "called_count: 12\n",
      "Loss: tensor(26713.0799, device='cuda:0') Last Loss: tensor(26736.7629, device='cuda:0') Reject Count: 0 Damping: 1.5625e-06\n",
      "Time 0.17806729125976561\n",
      "Loss: 13356.539968975932\n",
      "called_count: 13\n",
      "Loss: tensor(26705.1166, device='cuda:0') Last Loss: tensor(26713.0799, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.18267779541015625\n",
      "Loss: 13352.55830003688\n",
      "called_count: 14\n",
      "Loss: tensor(26701.0816, device='cuda:0') Last Loss: tensor(26705.1166, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.16950079345703126\n",
      "Loss: 13350.540777172806\n",
      "called_count: 15\n",
      "Loss: tensor(26698.6759, device='cuda:0') Last Loss: tensor(26701.0816, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.17224684143066407\n",
      "Loss: 13349.337940765343\n",
      "called_count: 16\n",
      "Loss: tensor(26697.0432, device='cuda:0') Last Loss: tensor(26698.6759, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.18140290832519532\n",
      "Loss: 13348.521612039222\n",
      "called_count: 17\n",
      "Loss: tensor(26695.8530, device='cuda:0') Last Loss: tensor(26697.0432, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.18191017150878908\n",
      "Loss: 13347.926482161814\n",
      "called_count: 18\n",
      "Loss: tensor(26694.9456, device='cuda:0') Last Loss: tensor(26695.8530, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.17888601684570313\n",
      "Loss: 13347.47281572242\n",
      "called_count: 19\n",
      "Loss: tensor(26694.2317, device='cuda:0') Last Loss: tensor(26694.9456, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.17744447326660157\n",
      "Loss: 13347.115857567556\n",
      "called_count: 20\n",
      "Loss: tensor(26693.6561, device='cuda:0') Last Loss: tensor(26694.2317, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.18422982788085937\n",
      "Loss: 13346.828036238981\n",
      "called_count: 21\n",
      "Loss: tensor(26693.1826, device='cuda:0') Last Loss: tensor(26693.6561, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.18354006958007812\n",
      "Loss: 13346.59132051701\n",
      "called_count: 22\n",
      "Loss: tensor(26692.7868, device='cuda:0') Last Loss: tensor(26693.1826, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.18233120727539062\n",
      "Loss: 13346.39340347261\n",
      "called_count: 23\n",
      "Loss: tensor(26692.4512, device='cuda:0') Last Loss: tensor(26692.7868, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.1786844482421875\n",
      "Loss: 13346.225601130083\n",
      "called_count: 24\n",
      "Loss: tensor(26692.1632, device='cuda:0') Last Loss: tensor(26692.4512, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.18046153259277345\n",
      "Loss: 13346.081616573023\n",
      "called_count: 25\n",
      "Loss: tensor(26691.9136, device='cuda:0') Last Loss: tensor(26692.1632, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.18304255676269532\n",
      "Loss: 13345.95677732498\n",
      "called_count: 26\n",
      "Loss: tensor(26691.6951, device='cuda:0') Last Loss: tensor(26691.9136, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.17933404541015624\n",
      "Loss: 13345.847546701141\n",
      "called_count: 27\n",
      "Loss: tensor(26691.5024, device='cuda:0') Last Loss: tensor(26691.6951, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.17698486328125\n",
      "Loss: 13345.751200819344\n",
      "called_count: 28\n",
      "Loss: tensor(26691.3312, device='cuda:0') Last Loss: tensor(26691.5024, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.17381747436523437\n",
      "Loss: 13345.665609379434\n",
      "called_count: 29\n",
      "Loss: tensor(26691.1782, device='cuda:0') Last Loss: tensor(26691.3312, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.1754998779296875\n",
      "Loss: 13345.589083406172\n",
      "called_count: 30\n",
      "Loss: tensor(26691.0405, device='cuda:0') Last Loss: tensor(26691.1782, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.17961299133300782\n",
      "Loss: 13345.520267330896\n",
      "called_count: 31\n",
      "Loss: tensor(26690.9161, device='cuda:0') Last Loss: tensor(26691.0405, device='cuda:0') Reject Count: 0 Damping: 1.5e-06\n",
      "Time 0.1707659454345703\n",
      "Loss: 13345.458061102025\n",
      "Ending loss: 13345.458061102025\n"
     ]
    }
   ],
   "source": [
    "\n",
    "camera_params_other = None if NUM_CAMERA_PARAMS == trimmed_dataset['camera_params'].shape[1] else trimmed_dataset['camera_params'][:, NUM_CAMERA_PARAMS:]\n",
    "input = {\"points_2d\": trimmed_dataset['points_2d'],\n",
    "         \"intr\": camera_params_other,\n",
    "         \"camera_indices\": trimmed_dataset['camera_index_of_observations'],\n",
    "         \"point_indices\": trimmed_dataset['point_index_of_observations']}\n",
    "\n",
    "# inverse quat\n",
    "def openGL2gtsam(pose):\n",
    "    R = pose.rotation()\n",
    "    t = pose.translation()\n",
    "    R90 = torch.eye(3, device=pose.device, dtype=pose.dtype)\n",
    "    R90[0, 0] = 1\n",
    "    R90[1, 1] = -1\n",
    "    R90[2, 2] = -1\n",
    "    wRc = R.Inv() @ pp.mat2SO3(R90)\n",
    "    t = R.Inv() @ -t\n",
    "    # // Our camera-to-world translation wTc = -R'*t\n",
    "    return pp.SE3(torch.cat([t, wRc], dim=-1))\n",
    "\n",
    "# gtsam coord\n",
    "# trimmed_dataset['camera_params'][:, :7] = Compose([pp.SE3, openGL2gtsam])(trimmed_dataset['camera_params'][:, :7])\n",
    "# trimmed_dataset['points_2d'][:, 1] = -trimmed_dataset['points_2d'][:, 1]\n",
    "\n",
    "model_non_batched = ReprojNonBatched(trimmed_dataset['camera_params'][:, :NUM_CAMERA_PARAMS].clone(),\n",
    "                                     trimmed_dataset['points_3d'].clone())\n",
    "\n",
    "model_non_batched = model_non_batched.to(DEVICE)\n",
    "\n",
    "# strategy_sparse = TrustRegion()\n",
    "strategy_sparse = pp.optim.strategy.Adaptive(damping=0.0001, min=1.5e-6)\n",
    "# sparse_solver = PCG(tol=1e-3, maxiter=10000)\n",
    "# sparse_solver = SciPySpSolver()\n",
    "sparse_solver = cuSolverSP()\n",
    "optimizer_sparse = LM(model_non_batched, strategy=strategy_sparse, solver=sparse_solver, reject=30)\n",
    "\n",
    "# least_square_error(camera_params, points_3d, camera_indices, point_indices, points_2d, intr=None)\n",
    "\n",
    "print('Starting loss:', least_square_error(model_non_batched.pose, model_non_batched.points_3d, trimmed_dataset['camera_index_of_observations'], trimmed_dataset['point_index_of_observations'], trimmed_dataset['points_2d'], intr=camera_params_other).item())\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "start.record()\n",
    "for idx in range(10):\n",
    "    loss = optimizer_sparse.step(input)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "end.record()\n",
    "print('Time', start.elapsed_time(end) / 1000)\n",
    "\n",
    "print('Loss:', least_square_error(model_non_batched.pose, model_non_batched.points_3d, trimmed_dataset['camera_index_of_observations'], trimmed_dataset['point_index_of_observations'], trimmed_dataset['points_2d'], intr=camera_params_other).item())\n",
    "print('Ending loss:', least_square_error(model_non_batched.pose, model_non_batched.points_3d, trimmed_dataset['camera_index_of_observations'], trimmed_dataset['point_index_of_observations'], trimmed_dataset['points_2d'], intr=camera_params_other).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
